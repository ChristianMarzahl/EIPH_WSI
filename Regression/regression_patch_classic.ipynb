{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from SlideRunner.dataAccess.database import Database\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import openslide\n",
    "from random import randint\n",
    "from Detection.data_loader import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/Datasets/EIPH_WSI/')\n",
    "\n",
    "database = Database()\n",
    "database.open(str(path/'EIPH.sqlite'))\n",
    "\n",
    "files = []\n",
    "lbl_bbox = []\n",
    "size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:00<00:07,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:01<00:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:02<00:14,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [00:02<00:12,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [00:02<00:10,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8/24 [00:03<00:06,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [00:03<00:04,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:03<00:03,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [00:04<00:01,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:04<00:01,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [00:05<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:06<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "getslides = \"\"\"SELECT uid, filename FROM Slides\"\"\"\n",
    "for currslide, filename in tqdm(database.execute(getslides).fetchall()):\n",
    "    database.loadIntoMemory(currslide)\n",
    "\n",
    "    check = True if 'erliner' in filename else False\n",
    "    slidetype = 'Berliner Blau/' if check else 'Turnbull Blue/'\n",
    "\n",
    "    slide_path = path / slidetype / filename\n",
    "\n",
    "    slide = openslide.open_slide(str(slide_path))\n",
    "    level = 1#slide.level_count - 1\n",
    "    level_dimension = slide.level_dimensions[level]\n",
    "    down_factor = slide.level_downsamples[level]\n",
    "\n",
    "    classes = {3: 0, 4: 1, 5: 2, 6: 3, 7: 4}\n",
    "    labels, bboxes = [], []\n",
    "    for id, annotation in database.annotations.items():\n",
    "        if annotation.labels[0].classId in classes:\n",
    "            d = 2 * annotation.r / down_factor\n",
    "            x_min = (annotation.x1 - annotation.r) / down_factor\n",
    "            y_min = (annotation.y1 - annotation.r) / down_factor\n",
    "            x_max = x_min + d\n",
    "            y_max = y_min + d\n",
    "            label = classes[annotation.labels[0].classId]\n",
    "\n",
    "            bboxes.append([int(x_min), int(y_min), int(x_max), int(y_max)])\n",
    "            labels.append(label)\n",
    "\n",
    "    if len(bboxes) > 0:\n",
    "        lbl_bbox.append([bboxes, labels])\n",
    "        files.append(SlideContainer(slide_path, level, size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2bbox = dict(zip(files, np.array(lbl_bbox)))\n",
    "get_y_func = lambda o:img2bbox[o]\n",
    "w, h = size, size\n",
    "\n",
    "num_examples_per_image = 100\n",
    "train_files = files[4:]\n",
    "valid_files = files[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_histogram_and_score(file: SlideContainer, boxes, labels, classes, num_examples_per_image):\n",
    "    image_x, image_y = [], []\n",
    "\n",
    "    for i in range(num_examples_per_image):\n",
    "        class_id = np.random.choice(classes, 1)[0]\n",
    "        ids = labels == class_id\n",
    "        xmin, ymin, xmax, ymax = np.array(boxes)[ids][randint(0, np.count_nonzero(ids) - 1)]\n",
    "\n",
    "        x = int(xmin - w / 2)\n",
    "        y = int(ymin - h / 2)\n",
    "\n",
    "        # select_boxes\n",
    "        select_boxes = np.copy(boxes)\n",
    "        select_boxes[:, [0, 2]] = select_boxes[:, [0, 2]] - x\n",
    "        select_boxes[:, [1, 3]] = select_boxes[:, [1, 3]] - y\n",
    "\n",
    "        bb_widths = (select_boxes[:, 2] - select_boxes[:, 0]) / 2\n",
    "        bb_heights = (select_boxes[:, 3] - select_boxes[:, 1]) / 2\n",
    "\n",
    "        ids = ((select_boxes[:, 0] + bb_widths) > 0) \\\n",
    "              & ((select_boxes[:, 1] + bb_heights) > 0) \\\n",
    "              & ((select_boxes[:, 2] - bb_widths) < w) \\\n",
    "              & ((select_boxes[:, 3] - bb_heights) < h)\n",
    "\n",
    "        select_labels = np.copy(labels)[ids]\n",
    "\n",
    "        patch = file.get_patch(x,y)\n",
    "        score = np.mean(select_labels)\n",
    "\n",
    "        histogram = np.concatenate((np.histogram(patch[:,:,0], bins=256)[0],\n",
    "                                    np.histogram(patch[:,:,1], bins=256)[0],\n",
    "                                    np.histogram(patch[:,:,2], bins=256)[0]))\n",
    "\n",
    "        image_x.append(histogram)\n",
    "        image_y.append(score)\n",
    "\n",
    "    return image_x, image_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = [], []\n",
    "val_x, val_y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:08<00:00,  5.29s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(train_files):\n",
    "\n",
    "    boxes, labels = get_y_func(file)\n",
    "    boxes = np.array(boxes)\n",
    "    labels = np.array(labels)\n",
    "    classes = list(set(labels))\n",
    "\n",
    "    x, y = extract_histogram_and_score(file,\n",
    "                                       boxes,\n",
    "                                       labels,\n",
    "                                       classes,\n",
    "                                       num_examples_per_image)\n",
    "    train_x.extend(x)\n",
    "    train_y.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:10<00:00,  5.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(valid_files):\n",
    "\n",
    "    boxes, labels = get_y_func(file)\n",
    "    boxes = np.array(boxes)\n",
    "    labels = np.array(labels)\n",
    "    classes = list(set(labels))\n",
    "\n",
    "    x, y = extract_histogram_and_score(file, boxes, labels,classes, num_examples_per_image)\n",
    "    val_x.extend(x)\n",
    "    val_y.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'train_x': train_x, 'train_y': train_y, 'val_x': val_x, 'val_y': val_y}\n",
    "pickle.dump( result, open( \"train_histo.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
