{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from SlideRunner.dataAccess.database import Database\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import openslide\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "from data_loader import *\n",
    "\n",
    "from helper.object_detection_helper import *\n",
    "from loss.RetinaNetFocalLoss import RetinaNetFocalLoss\n",
    "from models.RetinaNet import RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/Datasets/EIPH_WSI/')\n",
    "\n",
    "database = Database()\n",
    "database.open(str(path/'EIPH.sqlite'))\n",
    "\n",
    "size = 1024\n",
    "level = 0\n",
    "\n",
    "files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:00<00:00, 86.02it/s]\n"
     ]
    }
   ],
   "source": [
    "filenames = glob(str(path/'*'/'*.svs'), recursive=True)\n",
    "for filename in tqdm(filenames):\n",
    "\n",
    "    check = True if 'erliner' in filename else False\n",
    "    slidetype = 'Berliner Blau/' if check else 'Turnbull Blue/'\n",
    "\n",
    "    slide_path = path / slidetype / filename\n",
    "\n",
    "    slide = openslide.open_slide(str(slide_path))\n",
    "    level = level#slide.level_count - 1\n",
    "    level_dimension = slide.level_dimensions[level]\n",
    "    down_factor = slide.level_downsamples[level]\n",
    "\n",
    "    files.append(SlideContainer(slide_path,[[0], [1]], level, size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"pferd_0_1024_reg.pth\"\n",
    "\n",
    "state = torch.load(Path(path) / fname, map_location='cpu') \\\n",
    "    if defaults.device == torch.device('cpu') \\\n",
    "    else torch.load(Path(path) / fname)\n",
    "model = state.pop('model')\n",
    "mean = state['data']['normalize']['mean']\n",
    "std = state['data']['normalize']['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = create_anchors(sizes=[(32,32)], ratios=[1], scales=[0.6, 0.7, 0.9, 1.25, 1.5])\n",
    "detect_thresh = 0.1 \n",
    "nms_thresh = 0.3\n",
    "result_boxes = {}\n",
    "result_regression = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_box(bboxes, size: Tensor):\n",
    "    bboxes[:, :2] = bboxes[:, :2] - bboxes[:, 2:] / 2\n",
    "    bboxes[:, :2] = (bboxes[:, :2] + 1) * size / 2\n",
    "    bboxes[:, 2:] = bboxes[:, 2:] * size / 2\n",
    "    bboxes = bboxes.long()\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [14:42:22<00:00, 897.99s/it]   \n"
     ]
    }
   ],
   "source": [
    "debug_level = 1\n",
    "with torch.no_grad():\n",
    "    for slide_container in tqdm(files):\n",
    "\n",
    "        size = state['data']['tfmargs']['size']\n",
    "        result_boxes[slide_container.file.name] = []\n",
    "        result_regression[slide_container.file.name] = []\n",
    "\n",
    "        basepic = np.array(slide_container.slide.read_region(location=(0, 0),\n",
    "                                                             level=debug_level,\n",
    "                                                             size=slide_container.slide.level_dimensions[debug_level]))\n",
    "        basepic = basepic[:, :, :3].astype(np.uint8)\n",
    "\n",
    "        for x in range(0, slide_container.slide.level_dimensions[level][1] - 2 * size, 900): #int(size / 2)\n",
    "            for y in range(0, slide_container.slide.level_dimensions[level][0] - 2 * size, 900): #int(size / 2)\n",
    "                x_real = x  # * slide_container.down_factor, \\\n",
    "                y_real = y  # * slide_container.down_factor\n",
    "\n",
    "                patch_ori = slide_container.get_patch(x, y)\n",
    "                patch = pil2tensor(patch_ori / 255., np.float32)\n",
    "\n",
    "                patch = transforms.Normalize(mean, std)(patch)\n",
    "\n",
    "                class_pred_batch, bbox_pred_batch, _, regression_pred, bbox_regression_pred = model(\n",
    "                    patch[None, :, :, :])\n",
    "                for clas_pred, bbox_pred, reg_pred, box_reg_pred in zip(class_pred_batch, bbox_pred_batch,\n",
    "                                                                        regression_pred, bbox_regression_pred):\n",
    "\n",
    "                    result_regression[slide_container.file.name].append(\n",
    "                        np.array([x_real, y_real, x_real + size, y_real + size, reg_pred]))\n",
    "                    bbox_pred, scores, preds = process_output(clas_pred, bbox_pred, anchors, detect_thresh)\n",
    "\n",
    "                    if bbox_pred is not None:\n",
    "                        to_keep = nms(bbox_pred, scores, nms_thresh)\n",
    "                        bbox_pred, preds, scores = bbox_pred[to_keep].cpu(), preds[to_keep].cpu(), scores[to_keep].cpu()\n",
    "                        box_reg_pred = box_reg_pred[to_keep].cpu()\n",
    "\n",
    "                        t_sz = torch.Tensor([size, size])[None].float()\n",
    "\n",
    "                        bbox_pred = rescale_box(bbox_pred, t_sz)\n",
    "\n",
    "                        patch_ori = patch_ori.astype(np.uint8)\n",
    "                        for box, pred, score, bb_reg in zip(bbox_pred, preds, scores, box_reg_pred):\n",
    "                            y_box, x_box = box[:2]\n",
    "                            h, w = box[2:4]\n",
    "\n",
    "                            result_boxes[slide_container.file.name].append(np.array([x_box + x_real, y_box + y_real,\n",
    "                                                                                     x_box + x_real + w, y_box + y_real + h,\n",
    "                                                                                     pred, score, bb_reg]))\n",
    "\n",
    "                            cv2.rectangle(patch_ori, (int(x_box), int(y_box)), (int(x_box + w), int(y_box + h)),\n",
    "                                          (0, 0, 255), 1)\n",
    "\n",
    "                            y_box, x_box = box[:2] / slide.level_downsamples[debug_level]\n",
    "                            h, w = box[2:4] / slide.level_downsamples[debug_level]\n",
    "                            temp_x_real = x_real / slide.level_downsamples[debug_level]\n",
    "                            temp_y_real = y_real / slide.level_downsamples[debug_level]\n",
    "\n",
    "                            cv2.rectangle(basepic, (int(x_box + temp_x_real), int(y_box + temp_y_real)),\n",
    "                                          (int(x_box + temp_x_real + w), int(y_box + temp_y_real + h)), (255, 0, 0), 1)\n",
    "\n",
    "        cv2.imwrite(\"/server/born_pix_cm/{}.png\".format(slide_container.file.stem), basepic[:, :, [2, 1, 0]])\n",
    "        pickle.dump(result_boxes, open(\"inference_results_boxes_all.p\", \"wb\"))\n",
    "        pickle.dump(result_regression, open(\"inference_result_regression_all.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
