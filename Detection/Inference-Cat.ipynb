{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import openslide\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "from data_loader import *\n",
    "\n",
    "from helper.object_detection_helper import *\n",
    "from loss.RetinaNetFocalLoss import RetinaNetFocalLoss\n",
    "from models.RetinaNet import RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/Datasets/EIPH-Cat/')\n",
    "\n",
    "size = 1024\n",
    "level = 0\n",
    "\n",
    "files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 75.18it/s]\n"
     ]
    }
   ],
   "source": [
    "filenames = glob(str(path/'*.svs'), recursive=True)\n",
    "for filename in tqdm(filenames):\n",
    "\n",
    "    slide_path = path / filename\n",
    "\n",
    "    slide = openslide.open_slide(str(slide_path))\n",
    "    level = level#slide.level_count - 1\n",
    "    level_dimension = slide.level_dimensions[level]\n",
    "    down_factor = slide.level_downsamples[level]\n",
    "\n",
    "    files.append(SlideContainer(slide_path,[[0], [1]], level, size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'opt_func': functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)),\n",
       " 'loss_func': RetinaNetEIPHFocalLoss(\n",
       "   (reg_pred_loss): L1Loss()\n",
       " ),\n",
       " 'metrics': [PascalVOCMetric\n",
       "  anchors: tensor([[-0.9688, -0.9688,  0.1500,  0.1500],\n",
       "          [-0.9688, -0.9688,  0.1750,  0.1750],\n",
       "          [-0.9688, -0.9688,  0.2250,  0.2250],\n",
       "          ...,\n",
       "          [ 0.9688,  0.9688,  0.2250,  0.2250],\n",
       "          [ 0.9688,  0.9688,  0.3125,  0.3125],\n",
       "          [ 0.9688,  0.9688,  0.3750,  0.3750]])\n",
       "  size: 1024\n",
       "  metric_names: ['AP-0', 'AP-1', 'AP-2', 'AP-3', 'AP-4']\n",
       "  detect_thresh: 0.3\n",
       "  nms_thresh: 0.3\n",
       "  images_per_batch: 20],\n",
       " 'true_wd': True,\n",
       " 'bn_wd': True,\n",
       " 'wd': 0.01,\n",
       " 'train_bn': True,\n",
       " 'model_dir': 'models',\n",
       " 'callback_fns': [functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True),\n",
       "  fastai.train.ShowGraph,\n",
       "  callbacks.callbacks.BBMetrics],\n",
       " 'cb_state': {},\n",
       " 'model': RetinaNetEIPH(\n",
       "   (encoder): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace)\n",
       "     (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "     (4): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (5): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (6): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (7): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (c5top5): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (c5top6): Conv2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   (p6top7): Sequential(\n",
       "     (0): ReLU()\n",
       "     (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   )\n",
       "   (merges): ModuleList(\n",
       "     (0): LateralUpsampleMerge(\n",
       "       (conv_lat): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "     )\n",
       "     (1): LateralUpsampleMerge(\n",
       "       (conv_lat): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "     )\n",
       "   )\n",
       "   (smoothers): ModuleList(\n",
       "     (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       "   (classifier): Sequential(\n",
       "     (0): Sequential(\n",
       "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (3): Conv2d(128, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       "   (box_regressor): Sequential(\n",
       "     (0): Sequential(\n",
       "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (3): Conv2d(128, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       "   (classifier_image): Sequential(\n",
       "     (0): AdaptiveConcatPool2d(\n",
       "       (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "       (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "     )\n",
       "     (1): Flatten()\n",
       "     (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.25)\n",
       "     (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "     (5): ReLU(inplace)\n",
       "     (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (7): Dropout(p=0.5)\n",
       "     (8): Linear(in_features=512, out_features=1, bias=True)\n",
       "     (9): SigmoidRange()\n",
       "   )\n",
       "   (box_reg_classifier): Sequential(\n",
       "     (0): Sequential(\n",
       "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (3): Conv2d(128, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (4): SigmoidRange()\n",
       "   )\n",
       " ),\n",
       " 'data': {'x_cls': data_loader.ObjectItemListSlide,\n",
       "  'x_proc': [],\n",
       "  'y_cls': data_loader.SlideObjectCategoryList,\n",
       "  'y_proc': [<fastai.vision.data.ObjectCategoryProcessor at 0x7f0eccd66860>],\n",
       "  'tfms': [RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={'padding_mode': 'reflection', 'row_pct': 0.5, 'col_pct': 0.5}, do_run=True, is_random=True)],\n",
       "  'tfm_y': True,\n",
       "  'tfmargs': {'size': 1024},\n",
       "  'tfms_y': [RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={'padding_mode': 'reflection', 'row_pct': 0.5, 'col_pct': 0.5}, do_run=True, is_random=True)],\n",
       "  'tfmargs_y': {'size': 1024},\n",
       "  'normalize': {'mean': tensor([0.9314, 0.9058, 0.9214]),\n",
       "   'std': tensor([0.0771, 0.0864, 0.0624]),\n",
       "   'do_x': True,\n",
       "   'do_y': False}},\n",
       " 'cls': fastai.basic_train.Learner}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(Path(path)/ fname, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"pferd_0_1024_reg.pth\"\n",
    "\n",
    "state = torch.load(Path(path) / fname, map_location='cpu') \\\n",
    "    if defaults.device == torch.device('cpu') \\\n",
    "    else torch.load(Path(path) / fname)\n",
    "model = state.pop('model')\n",
    "mean = state['data']['normalize']['mean']\n",
    "std = state['data']['normalize']['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetinaNetEIPH(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (c5top5): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (c5top6): Conv2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (p6top7): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (merges): ModuleList(\n",
       "    (0): LateralUpsampleMerge(\n",
       "      (conv_lat): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): LateralUpsampleMerge(\n",
       "      (conv_lat): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (smoothers): ModuleList(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Conv2d(128, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (box_regressor): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Conv2d(128, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (classifier_image): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (9): SigmoidRange()\n",
       "  )\n",
       "  (box_reg_classifier): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Conv2d(128, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): SigmoidRange()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = create_anchors(sizes=[(32,32)], ratios=[1], scales=[0.6, 0.7, 0.9, 1.25, 1.5])\n",
    "detect_thresh = 0.1 \n",
    "nms_thresh = 0.3\n",
    "result_boxes = {}\n",
    "result_regression = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_box(bboxes, size: Tensor):\n",
    "    bboxes[:, :2] = bboxes[:, :2] - bboxes[:, 2:] / 2\n",
    "    bboxes[:, :2] = (bboxes[:, :2] + 1) * size / 2\n",
    "    bboxes[:, 2:] = bboxes[:, 2:] * size / 2\n",
    "    bboxes = bboxes.long()\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 1/14 [13:36<2:57:00, 816.94s/it]\u001b[A\n",
      " 14%|█▍        | 2/14 [29:09<2:50:17, 851.48s/it]\u001b[A\n",
      " 21%|██▏       | 3/14 [42:26<2:33:07, 835.22s/it]\u001b[A\n",
      " 29%|██▊       | 4/14 [57:27<2:22:31, 855.10s/it]\u001b[A\n",
      " 36%|███▌      | 5/14 [1:10:27<2:04:51, 832.43s/it]\u001b[A\n",
      " 43%|████▎     | 6/14 [1:24:06<1:50:26, 828.37s/it]\u001b[A\n",
      " 50%|█████     | 7/14 [1:36:43<1:34:09, 807.04s/it]\u001b[A\n",
      " 57%|█████▋    | 8/14 [1:49:46<1:19:58, 799.80s/it]\u001b[A\n",
      " 64%|██████▍   | 9/14 [2:04:00<1:08:00, 816.18s/it]\u001b[A\n",
      " 71%|███████▏  | 10/14 [2:18:15<55:11, 827.87s/it] \u001b[A\n",
      " 79%|███████▊  | 11/14 [2:31:48<41:09, 823.24s/it]\u001b[A\n",
      " 86%|████████▌ | 12/14 [2:47:39<28:43, 861.55s/it]\u001b[A\n",
      " 93%|█████████▎| 13/14 [3:04:20<15:03, 903.51s/it]\u001b[A\n",
      "100%|██████████| 14/14 [3:17:38<00:00, 871.68s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "debug_level = 1\n",
    "with torch.no_grad():\n",
    "    for slide_container in tqdm(files):\n",
    "\n",
    "        size = state['data']['tfmargs']['size']\n",
    "        result_boxes[slide_container.file.name] = []\n",
    "        result_regression[slide_container.file.name] = []\n",
    "\n",
    "        basepic = np.array(slide_container.slide.read_region(location=(0, 0),\n",
    "                                                             level=debug_level,\n",
    "                                                             size=slide_container.slide.level_dimensions[debug_level]))\n",
    "        basepic = basepic[:, :, :3].astype(np.uint8)\n",
    "\n",
    "        for x in range(0, slide_container.slide.level_dimensions[level][1] - 2 * size, 900): #int(size / 2)\n",
    "            for y in range(0, slide_container.slide.level_dimensions[level][0] - 2 * size, 900): #int(size / 2)\n",
    "                x_real = x  # * slide_container.down_factor, \\\n",
    "                y_real = y  # * slide_container.down_factor\n",
    "\n",
    "                patch_ori = slide_container.get_patch(x, y)\n",
    "                patch = pil2tensor(patch_ori / 255., np.float32)\n",
    "\n",
    "                patch = transforms.Normalize(mean, std)(patch)\n",
    "\n",
    "                class_pred_batch, bbox_pred_batch, _, regression_pred, bbox_regression_pred = model.eval()(\n",
    "                    patch[None, :, :, :])\n",
    "                for clas_pred, bbox_pred, reg_pred, box_reg_pred in zip(class_pred_batch, bbox_pred_batch,\n",
    "                                                                        regression_pred, bbox_regression_pred):\n",
    "\n",
    "                    result_regression[slide_container.file.name].append(\n",
    "                        np.array([x_real, y_real, x_real + size, y_real + size, reg_pred]))\n",
    "                    bbox_pred, scores, preds = process_output(clas_pred, bbox_pred, anchors, detect_thresh)\n",
    "\n",
    "                    if bbox_pred is not None:\n",
    "                        to_keep = nms(bbox_pred, scores, nms_thresh)\n",
    "                        bbox_pred, preds, scores = bbox_pred[to_keep].cpu(), preds[to_keep].cpu(), scores[to_keep].cpu()\n",
    "                        box_reg_pred = box_reg_pred[to_keep].cpu()\n",
    "\n",
    "                        t_sz = torch.Tensor([size, size])[None].float()\n",
    "\n",
    "                        bbox_pred = rescale_box(bbox_pred, t_sz)\n",
    "\n",
    "                        patch_ori = patch_ori.astype(np.uint8)\n",
    "                        for box, pred, score, bb_reg in zip(bbox_pred, preds, scores, box_reg_pred):\n",
    "                            y_box, x_box = box[:2]\n",
    "                            h, w = box[2:4]\n",
    "\n",
    "                            result_boxes[slide_container.file.name].append(np.array([x_box + x_real, y_box + y_real,\n",
    "                                                                                     x_box + x_real + w, y_box + y_real + h,\n",
    "                                                                                     pred, score, bb_reg]))\n",
    "\n",
    "                            cv2.rectangle(patch_ori, (int(x_box), int(y_box)), (int(x_box + w), int(y_box + h)),\n",
    "                                          (0, 0, 255), 1)\n",
    "\n",
    "                            y_box, x_box = box[:2] / slide.level_downsamples[debug_level]\n",
    "                            h, w = box[2:4] / slide.level_downsamples[debug_level]\n",
    "                            temp_x_real = x_real / slide.level_downsamples[debug_level]\n",
    "                            temp_y_real = y_real / slide.level_downsamples[debug_level]\n",
    "\n",
    "                            cv2.rectangle(basepic, (int(x_box + temp_x_real), int(y_box + temp_y_real)),\n",
    "                                          (int(x_box + temp_x_real + w), int(y_box + temp_y_real + h)), (255, 0, 0), 1)\n",
    "\n",
    "        #cv2.imwrite(\"/server/born_pix_cm/{}.png\".format(slide_container.file.stem), basepic[:, :, [2, 1, 0]])\n",
    "        pickle.dump(result_boxes, open(str(path/\"inference_results_boxes_all.p\"), \"wb\"))\n",
    "        pickle.dump(result_regression, open(str(path/\"inference_result_regression_all.p\"), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
