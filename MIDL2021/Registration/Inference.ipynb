{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import openslide\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "from object_detection_fastai.helper.wsi_loader import SlideContainer\n",
    "from object_detection_fastai.helper.object_detection_helper import *\n",
    "from object_detection_fastai.loss.RetinaNetFocalLoss import RetinaNetFocalLoss\n",
    "from object_detection_fastai.models.RetinaNet import RetinaNet\n",
    "from object_detection_fastai.helper.nms_center_distance import non_max_suppression_by_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_box(bboxes, size: Tensor):\n",
    "    bboxes[:, :2] = bboxes[:, :2] - bboxes[:, 2:] / 2\n",
    "    bboxes[:, :2] = (bboxes[:, :2] + 1) * size / 2\n",
    "    bboxes[:, 2:] = bboxes[:, 2:] * size / 2\n",
    "    bboxes = bboxes.long()\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1024\n",
    "level = 0\n",
    "\n",
    "files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../Slides/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../Slides/Aperio/24_EIPH_576255 Berliner Blau.svs'),\n",
       " WindowsPath('../Slides/AxioScan/Z_BB_576255_1.tif'),\n",
       " WindowsPath('../Slides/NanoZoomer2.0HT/N2_BB_576255_1.ndpi'),\n",
       " WindowsPath('../Slides/NanoZoomerS210/N1_BB_576255_1.ndpi')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(path.glob(\"*/*.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 10.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for slide_path in tqdm(path.glob(\"*/*.*\")):\n",
    "    \n",
    "    slide = openslide.open_slide(str(slide_path))\n",
    "    level = level#slide.level_count - 1\n",
    "    level_dimension = slide.level_dimensions[level]\n",
    "    down_factor = slide.level_downsamples[level]\n",
    "\n",
    "    files.append(SlideContainer(slide_path,[[0], [1]], level, size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NanoZoomerS210'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_path.parent.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetinaNet(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (c5top5): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (c5top6): Conv2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (p6top7): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (merges): ModuleList(\n",
       "    (0): LateralUpsampleMerge(\n",
       "      (conv_lat): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): LateralUpsampleMerge(\n",
       "      (conv_lat): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (smoothers): ModuleList(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Conv2d(128, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (box_regressor): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Conv2d(128, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = \"Equine-Fold-2.p\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model_information = torch.load(model_file, map_location='cpu') \\\n",
    "                    if torch.cuda.is_available() ==  False \\\n",
    "                    else torch.load(model_file)\n",
    "\n",
    "model_weights = model_information['model']\n",
    "anchors = model_information[\"anchors\"]\n",
    "mean = model_information[\"mean\"]\n",
    "std = model_information[\"std\"]\n",
    "shape = model_information[\"size\"]\n",
    "n_classes = model_information['n_classes']\n",
    "n_anchors = model_information['n_anchors']\n",
    "sizes = model_information['sizes']\n",
    "chs = model_information['chs']\n",
    "encoder = model_information['encoder']\n",
    "n_conv = model_information['n_conv']\n",
    "level = model_information['level']\n",
    "\n",
    "\n",
    "encoder = create_body(models.resnet18, False, -2)\n",
    "\n",
    "model = RetinaNet(encoder, n_classes, n_anchors=n_anchors, sizes=sizes,\n",
    "                                       chs=chs, n_conv=3)\n",
    "model.load_state_dict(model_weights)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_thresh = 0.3 \n",
    "nms_thresh = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [38:44<00:00, 581.18s/it]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "debug_level = 1\n",
    "annotations = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for slide_container in tqdm(files):\n",
    "        \n",
    "        image_boxes = []\n",
    "        \n",
    "        for x in range(0, slide_container.slide.level_dimensions[level][0] - 2 * size, 750): #int(size / 2)\n",
    "            for y in range(0, slide_container.slide.level_dimensions[level][1] - 2 * size, 750): #int(size / 2)\n",
    "                x_real = x  # * slide_container.down_factor, \\\n",
    "                y_real = y  # * slide_container.down_factor\n",
    "\n",
    "                patch_ori = slide_container.get_patch(x, y)\n",
    "                patch = pil2tensor(patch_ori / 255., np.float32)\n",
    "\n",
    "                patch = transforms.Normalize(mean, std)(patch)\n",
    "\n",
    "                class_pred_batch, bbox_pred_batch, _ = model.eval()(\n",
    "                    patch[None, :, :, :].cuda())\n",
    "                for clas_pred, bbox_pred in zip(class_pred_batch, bbox_pred_batch):\n",
    "\n",
    "                    bbox_pred, scores, preds = process_output(clas_pred, bbox_pred, anchors, detect_thresh)\n",
    "\n",
    "                    if bbox_pred is not None:\n",
    "                        to_keep = nms(bbox_pred, scores, nms_thresh)\n",
    "                        bbox_pred, preds, scores = bbox_pred[to_keep].cpu(), preds[to_keep].cpu(), scores[to_keep].cpu()\n",
    "\n",
    "                        t_sz = torch.Tensor([size, size])[None].float()\n",
    "\n",
    "                        bbox_pred = rescale_box(bbox_pred, t_sz)\n",
    "\n",
    "                        patch_ori = patch_ori.astype(np.uint8)\n",
    "                        for box, pred, score in zip(bbox_pred, preds, scores):\n",
    "                            y_box, x_box = box[:2]\n",
    "                            h, w = box[2:4]\n",
    "                            scale = float(w) / float(h)\n",
    "                            \n",
    "                            if scale > 0.9 and scale < 1.1:\n",
    "                                \n",
    "                                image_boxes.append([int(x_box + x_real), int(y_box + y_real), int(x_box + x_real + w), \n",
    "                                    int(y_box + y_real + h), int(pred), float(score)])                        \n",
    "                                \n",
    "        boxes = np.array(image_boxes)\n",
    "        annos = non_max_suppression_by_distance(boxes, boxes[:, 5], 40)\n",
    "        \n",
    "        for anno in annos:       \n",
    "                                \n",
    "            annotations.append([str(slide_container.file.name), str(slide_container.file.parent.stem), \"576255\",\n",
    "                                        slide_container.slide.level_dimensions[0][0], \n",
    "                                        slide_container.slide.level_dimensions[0][1],\n",
    "                                        anno[0], anno[1], anno[2], anno[3], anno[4], anno[5]])\n",
    "                            \n",
    "                \n",
    "            \n",
    "\n",
    "        df = pd.DataFrame(annotations, columns=[\"file\", \"scanner\", \"image_nr\", \"width\", \"height\" , \"x1\", \"y1\", \"x2\", \"y2\", \"label\", \"score\"])\n",
    "        df.to_pickle(\"reg_results.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>scanner</th>\n",
       "      <th>image_nr</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24_EIPH_576255 Berliner Blau.svs</td>\n",
       "      <td>NanoZoomerS210</td>\n",
       "      <td>576255</td>\n",
       "      <td>34200</td>\n",
       "      <td>32356</td>\n",
       "      <td>10978.0</td>\n",
       "      <td>7036.0</td>\n",
       "      <td>11107.0</td>\n",
       "      <td>7166.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.929032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24_EIPH_576255 Berliner Blau.svs</td>\n",
       "      <td>NanoZoomerS210</td>\n",
       "      <td>576255</td>\n",
       "      <td>34200</td>\n",
       "      <td>32356</td>\n",
       "      <td>30033.0</td>\n",
       "      <td>13813.0</td>\n",
       "      <td>30201.0</td>\n",
       "      <td>13981.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.926395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24_EIPH_576255 Berliner Blau.svs</td>\n",
       "      <td>NanoZoomerS210</td>\n",
       "      <td>576255</td>\n",
       "      <td>34200</td>\n",
       "      <td>32356</td>\n",
       "      <td>18278.0</td>\n",
       "      <td>4283.0</td>\n",
       "      <td>18394.0</td>\n",
       "      <td>4399.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24_EIPH_576255 Berliner Blau.svs</td>\n",
       "      <td>NanoZoomerS210</td>\n",
       "      <td>576255</td>\n",
       "      <td>34200</td>\n",
       "      <td>32356</td>\n",
       "      <td>25220.0</td>\n",
       "      <td>11058.0</td>\n",
       "      <td>25328.0</td>\n",
       "      <td>11167.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24_EIPH_576255 Berliner Blau.svs</td>\n",
       "      <td>NanoZoomerS210</td>\n",
       "      <td>576255</td>\n",
       "      <td>34200</td>\n",
       "      <td>32356</td>\n",
       "      <td>12767.0</td>\n",
       "      <td>22738.0</td>\n",
       "      <td>12885.0</td>\n",
       "      <td>22856.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.922600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file         scanner image_nr  width  height  \\\n",
       "0  24_EIPH_576255 Berliner Blau.svs  NanoZoomerS210   576255  34200   32356   \n",
       "1  24_EIPH_576255 Berliner Blau.svs  NanoZoomerS210   576255  34200   32356   \n",
       "2  24_EIPH_576255 Berliner Blau.svs  NanoZoomerS210   576255  34200   32356   \n",
       "3  24_EIPH_576255 Berliner Blau.svs  NanoZoomerS210   576255  34200   32356   \n",
       "4  24_EIPH_576255 Berliner Blau.svs  NanoZoomerS210   576255  34200   32356   \n",
       "\n",
       "        x1       y1       x2       y2  label     score  \n",
       "0  10978.0   7036.0  11107.0   7166.0    4.0  0.929032  \n",
       "1  30033.0  13813.0  30201.0  13981.0    2.0  0.926395  \n",
       "2  18278.0   4283.0  18394.0   4399.0    1.0  0.926342  \n",
       "3  25220.0  11058.0  25328.0  11167.0    1.0  0.925790  \n",
       "4  12767.0  22738.0  12885.0  22856.0    1.0  0.922600  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38400, 39424)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_container.slide.level_dimensions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NanoZoomerS210'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"scanner\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33412"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NanoZoomerS210'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_container.file.parent.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../Slides/Aperio/24_EIPH_576255 Berliner Blau.svs'),\n",
       " WindowsPath('../Slides/AxioScan/Z_BB_576255_1.tif'),\n",
       " WindowsPath('../Slides/NanoZoomer2.0HT/N2_BB_576255_1.ndpi'),\n",
       " WindowsPath('../Slides/NanoZoomerS210/N1_BB_576255_1.ndpi')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[temp.file for temp in files] #.parent.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
