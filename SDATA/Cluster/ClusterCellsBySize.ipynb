{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import openslide\n",
    "import pyvips\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exact_sync.v1.api.annotations_api import AnnotationsApi\n",
    "from exact_sync.v1.api.images_api import ImagesApi\n",
    "from exact_sync.v1.api.image_sets_api import ImageSetsApi\n",
    "from exact_sync.v1.api.annotation_types_api import AnnotationTypesApi\n",
    "from exact_sync.v1.api.products_api import ProductsApi\n",
    "from exact_sync.v1.api.teams_api import TeamsApi\n",
    "\n",
    "from exact_sync.v1.models import ImageSet, Team, Product, AnnotationType, Image, Annotation, AnnotationMediaFile\n",
    "from exact_sync.v1.rest import ApiException\n",
    "from exact_sync.v1.configuration import Configuration\n",
    "from exact_sync.v1.api_client import ApiClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to EXACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'marzahl'\n",
    "password = '****'\n",
    "wsi_paths = \"D:\\\\Datasets\\\\EIPH WSI\\\\Katze\"\n",
    "host =  \"https://exact.cs.fau.de/\"\n",
    "\n",
    "source_dataset = \"Felidae-EIPH\"\n",
    "target_dataset = \"Felidae-EIPH-Cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_configuration = Configuration()\n",
    "local_configuration.username = username\n",
    "local_configuration.password = password\n",
    "local_configuration.host =  host\n",
    "\n",
    "local_client = ApiClient(local_configuration)\n",
    "\n",
    "local_image_sets_api = ImageSetsApi(local_client)\n",
    "local_annotations_api = AnnotationsApi(local_client)\n",
    "local_annotation_types_api = AnnotationTypesApi(local_client)\n",
    "local_images_api = ImagesApi(local_client)\n",
    "local_product_api = ProductsApi(local_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlaod annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_sets = local_image_sets_api.list_image_sets(name=source_dataset)\n",
    "target_image_set = local_image_sets_api.list_image_sets(name=target_dataset).results[0]\n",
    "\n",
    "local_images = {}\n",
    "local_annotation_types = {}\n",
    "\n",
    "for local_image_set in local_image_sets.results:\n",
    "    for image in local_images_api.list_images(pagination=False, image_set=local_image_set.id).results:\n",
    "        local_images[image.name] = image\n",
    "    for product in local_image_set.product_set:\n",
    "        for anno_type in local_annotation_types_api.list_annotation_types(product=product).results:\n",
    "            local_annotation_types[anno_type.id] = anno_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {p.name:p for p in Path(wsi_paths).glob(\"**/*.svs\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 0\n",
    "down_factor = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the cells to new images clustered by their width to height ratio.\n",
    "\n",
    " [***2.6  Semi-automatic data cleaning via customised clustering***](https://arxiv.org/abs/2108.08529)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "for image in tqdm(local_images.values()):\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    y_total_size = 5000\n",
    "    x_total_size = 10000\n",
    "    x_border = 10\n",
    "    y_border = 10\n",
    "\n",
    "    big_image = np.zeros(shape=(y_total_size, x_total_size, 3), dtype=np.uint8)\n",
    "    big_image += 255\n",
    "\n",
    "\n",
    "    slide_path = files[image.name]\n",
    "    target_file = Path(image.name.replace(\"svs\", \"tiff\"))\n",
    "\n",
    "    local_annos = local_annotations_api.list_annotations(image=image.id, pagination=False).results\n",
    "    data = [[anno.unique_identifier, anno.vector['x1'], anno.vector['y1'], anno.vector['x2'], anno.vector['y2'], anno.annotation_type, anno.meta_data]  for anno in local_annos]\n",
    "    \n",
    "    vector_data = np.array([[anno.vector['x1'], anno.vector['y1'], anno.vector['x2'], anno.vector['y2']]  for anno in local_annos])\n",
    "\n",
    "    slide = openslide.open_slide(str(slide_path))\n",
    "\n",
    "    df = pd.DataFrame(data=data, columns=[\"unique_identifier\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"label\", \"meta_data\"])\n",
    "    df[\"width\"] = vector_data[:, 2] -  vector_data[:, 0]\n",
    "    df[\"hight\"] = vector_data[:, 3] -  vector_data[:, 1]\n",
    "\n",
    "    x_start = 0\n",
    "    y_start = y_total_size\n",
    "    x_max = 0\n",
    "\n",
    "    for width in tqdm(sorted(df[\"width\"].unique())):\n",
    "        df_width = df[df[\"width\"] == width].sort_values(by=['hight', 'label'])\n",
    "\n",
    "        x_start = x_max + x_border\n",
    "        y_start = y_total_size\n",
    "\n",
    "        for offset_x, offset_y, w, h, label, meta_data,unique_identifier  in zip(df_width[\"x_min\"], df_width[\"y_min\"], df_width[\"width\"], df_width[\"hight\"], df_width[\"label\"], df_width[\"meta_data\"], df_width[\"unique_identifier\"]):\n",
    "            offset_x, offset_y, w, h = int(offset_x), int(offset_y), int(w), int(h)\n",
    "\n",
    "            # if image hight is reached start with new column\n",
    "            if y_start - h  <= 0:\n",
    "                y_start = y_total_size\n",
    "                x_start = x_max + x_border\n",
    "\n",
    "            # if end of bin image increase big image size\n",
    "            if x_start + w >= x_total_size:\n",
    "                z = np.zeros((y_total_size, max(1000, w), 3), dtype=np.uint8)\n",
    "                z += 255\n",
    "                big_image = np.concatenate((big_image, z), axis=1)\n",
    "\n",
    "                x_total_size += max(1000, w)\n",
    "\n",
    "            patch = np.array(slide.read_region(location=(int(offset_x * down_factor), int(offset_y * down_factor)),\n",
    "                                                level=level, size=(w, h)))[:, :, :3]\n",
    "\n",
    "\n",
    "            min_y = y_start - h\n",
    "            max_y = y_start\n",
    "            big_image[min_y:max_y, x_start:x_start+w] = patch\n",
    "\n",
    "            \n",
    "            vector = {\"x1\": x_start + 5, \"y1\": min_y + 5, \"x2\": x_start + w - 5, \"y2\": max_y - 5}\n",
    "            \n",
    "            annotation = Annotation(annotation_type=label, vector=vector, unique_identifier=unique_identifier, meta_data=meta_data)\n",
    "            annotations.append(annotation)\n",
    "\n",
    "            y_start -= (h + y_border)\n",
    "            x_max = max(x_max, x_start+w)\n",
    "            \n",
    "    height, width, bands = big_image.shape\n",
    "    linear = big_image.reshape(width * height * bands)\n",
    "    vi = pyvips.Image.new_from_memory(linear.data, width, height, bands, 'uchar')\n",
    "    vi.tiffsave(str(target_file), tile=True, compression='lzw', bigtiff=True, pyramid=True)\n",
    "\n",
    "        \n",
    "    image_type = int(Image.ImageSourceTypes.SERVER_GENERATED)\n",
    "    new_image = local_images_api.create_image(file_path=target_file, image_type=image_type, image_set=target_image_set.id).results[0]\n",
    "    \n",
    "    for anno in annotations:\n",
    "        anno.image = new_image.id\n",
    "\n",
    "        thread = local_annotations_api.create_annotation(body=anno, async_req=True)\n",
    "        threads.append(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait until all annotations are in sync with the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "while (len(threads) > 0):\n",
    "    if len(threads) % 1000:\n",
    "        print(len(threads))\n",
    "    for thread in threads:\n",
    "        if thread.ready():\n",
    "            threads.remove(thread)\n",
    "    sleep(0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
