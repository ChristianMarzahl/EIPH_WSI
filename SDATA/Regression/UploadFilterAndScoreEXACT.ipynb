{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from object_detection_fastai.helper.nms_center_distance import non_max_suppression_by_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.callbacks.hooks import params_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openslide\n",
    "import cv2\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exact_sync.v1.configuration import Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('D:/Datasets/EIPH WSI/Pferd/Patches/train')\n",
    "files = {p.name:p for p in Path(\"D:\\\\Datasets\\\\EIPH WSI\\\\Humane\").glob(\"**/*.svs\")}\n",
    "\n",
    "learn = load_learner(path)\n",
    "\n",
    "configuration = Configuration()\n",
    "configuration.username = 'marzahl'\n",
    "configuration.password = 'imagetagger'\n",
    "configuration.host =  \"https://exact.cs.fau.de/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync results with server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting EXCAT-Sync\n",
      "  Downloading EXCAT_Sync-0.0.18-py3-none-any.whl (116 kB)\n",
      "Installing collected packages: EXCAT-Sync\n",
      "  Attempting uninstall: EXCAT-Sync\n",
      "    Found existing installation: EXCAT-Sync 0.0.17\n",
      "    Uninstalling EXCAT-Sync-0.0.17:\n",
      "      Successfully uninstalled EXCAT-Sync-0.0.17\n",
      "Successfully installed EXCAT-Sync-0.0.18\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade EXCAT-Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exact_sync.v1.api.annotations_api import AnnotationsApi\n",
    "from exact_sync.v1.api.images_api import ImagesApi\n",
    "from exact_sync.v1.api.image_sets_api import ImageSetsApi\n",
    "from exact_sync.v1.api.annotation_types_api import AnnotationTypesApi\n",
    "from exact_sync.v1.api.products_api import ProductsApi\n",
    "from exact_sync.v1.api.teams_api import TeamsApi\n",
    "\n",
    "from exact_sync.v1.models import ImageSet, Team, Product, AnnotationType, Image, Annotation, AnnotationMediaFile\n",
    "from exact_sync.v1.rest import ApiException\n",
    "from exact_sync.v1.api_client import ApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ApiClient(configuration)\n",
    "\n",
    "image_sets_api = ImageSetsApi(client)\n",
    "annotations_api = AnnotationsApi(client)\n",
    "annotation_types_api = AnnotationTypesApi(client)\n",
    "images_api = ImagesApi(client)\n",
    "product_api = ProductsApi(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'creator': 1,\n",
       "  'description': '',\n",
       "  'id': 251,\n",
       "  'images': [3627,\n",
       "             3623,\n",
       "             3622,\n",
       "             3600,\n",
       "             3601,\n",
       "             3602,\n",
       "             3603,\n",
       "             3604,\n",
       "             3605,\n",
       "             3606,\n",
       "             3607,\n",
       "             3608,\n",
       "             3609,\n",
       "             3610,\n",
       "             3611,\n",
       "             3612,\n",
       "             3613,\n",
       "             3614,\n",
       "             3615,\n",
       "             3616,\n",
       "             3617],\n",
       "  'location': None,\n",
       "  'main_annotation_type': 6,\n",
       "  'name': 'Humane-EIPH',\n",
       "  'path': 'imagetagger_4_251',\n",
       "  'product_set': [3],\n",
       "  'set_tags': [],\n",
       "  'team': 4}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_sets = image_sets_api.list_image_sets(name__contains=\"Humane-EIPH\")\n",
    "image_sets.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "annotation_types = {}\n",
    "\n",
    "for image_set in image_sets.results:\n",
    "    for image in images_api.list_images(pagination=False, image_set=image_set.id).results:\n",
    "        images[image.name] = image\n",
    "    for product in image_set.product_set:\n",
    "        for anno_type in annotation_types_api.list_annotation_types(product=product).results:\n",
    "            annotation_types[anno_type.name] = anno_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2702_20 BB Human BAL-001.svs': {'annotations': 'Annotations not load please remove omit=annotations',\n",
       "  'filename': '2702_20 BB Human BAL-001.svs',\n",
       "  'height': 32360,\n",
       "  'id': 3627,\n",
       "  'image_set': 251,\n",
       "  'image_type': 0,\n",
       "  'mpp': 0.2533,\n",
       "  'name': '2702_20 BB Human BAL-001.svs',\n",
       "  'objective_power': 40.0,\n",
       "  'time': datetime.datetime(2020, 8, 29, 12, 20, 18, 133678),\n",
       "  'width': 34200}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_results = Path('D:/Datasets/EIPH WSI/Humane/3627_human.p')\n",
    "resultsArchive = pickle.load(open(str(inference_results),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13136/13136 [28:02<00:00,  7.81it/s]\n"
     ]
    }
   ],
   "source": [
    "down_factor = 1\n",
    "level = 0\n",
    "nms_thresh = 40 \n",
    "thresh = 0.35\n",
    "\n",
    "mean, std = learn.data.stats\n",
    "\n",
    "device = torch.device('cpu')\n",
    "cpu_model = learn.model.to(device)\n",
    "\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for image_name in images:\n",
    "        \n",
    "        image = images[image_name]\n",
    "        \n",
    "        boxes = np.array(resultsArchive[image.name])\n",
    "        boxes = boxes[boxes[:,5].argsort()]\n",
    "        annos = non_max_suppression_by_distance(boxes, boxes[:, 5], nms_thresh)\n",
    "        annos = annos[annos[:, 5] > thresh]\n",
    "        \n",
    "        for idx in tqdm(range(len(annos))):\n",
    "            row = annos[idx]\n",
    "            \n",
    "            x_min = int(row[0]) \n",
    "            y_min = int(row[1]) \n",
    "            x_max = int(row[2]) \n",
    "            y_max = int(row[3])\n",
    "            label = int(row[4])\n",
    "            \n",
    "            w, h = x_max - x_min, y_max - y_min\n",
    "            \n",
    "            if x_max - x_min < 10 or y_max - y_min < 10:\n",
    "                continue\n",
    "        \n",
    "            deleted = False\n",
    "            if w / h < 0.9 or w / h > 1.1:\n",
    "                deleted = True\n",
    "        \n",
    "            vector = {\"x1\": x_min, \"y1\": y_min, \"x2\": x_max, \"y2\": y_max}\n",
    "            annotation_type = annotation_types[str(label)]\n",
    "            \n",
    "            slide_path = files[image.name]\n",
    "            slide = openslide.open_slide(str(slide_path))\n",
    "            \n",
    "            patch = np.array(slide.read_region(location=(int(x_min * down_factor), int(y_min * down_factor)),\n",
    "                                                level=level, size=(w, h)))[:, :, :3]\n",
    "\n",
    "            patch = cv2.resize(patch, (128, 128))\n",
    "            patch = pil2tensor(patch / 255., np.float32)\n",
    "            patch = transforms.Normalize(mean, std)(patch)\n",
    "\n",
    "            score = cpu_model.eval()(patch[None, :, :, :])\n",
    "        \n",
    "            meta = {'Score': float(score)}\n",
    "            \n",
    "            annotation = Annotation(annotation_type=annotation_type.id, vector=vector, image=image.id, deleted=deleted, meta_data=meta)\n",
    "            results.append(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13136/13136 [43:26<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for annotation in tqdm(results):\n",
    "    annotations_api.create_annotation(body=annotation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
