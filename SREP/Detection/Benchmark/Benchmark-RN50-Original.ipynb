{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.object_detection_helper import *\n",
    "from loss.RetinaNetFocalLoss import RetinaNetFocalLoss\n",
    "from models.RetinaNet import RetinaNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helper.nms_center_distance import non_max_suppression_by_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_func(x):\n",
    "    return [[[0,0,0,0], [0,0,0,0], [0,0,0,0], [0,0,0,0], [0,0,0,0]], [1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/Datasets/EIPH_WSI/RCNN-Patches/Inference/11_EIPH_575697 Berliner Blau')\n",
    "bs = 4\n",
    "data = (ObjectItemList.from_folder(path)\n",
    "        #Where are the images? -> in coco\n",
    "        .split_none()\n",
    "        #How to split in train/valid? -> randomly with the default 20% in valid\n",
    "        .label_from_func(get_y_func)\n",
    "        #How to find the labels? -> use get_y_func\n",
    "        .transform(get_transforms(), tfm_y=True, size=1024)\n",
    "        #Data augmentation? -> Standard transforms with tfm_y=True\n",
    "        .databunch(bs=bs, collate_fn=bb_pad_collate))\\\n",
    "    .normalize([[0.9296, 0.9177, 0.9290], [0.0986, 0.0931, 0.0679]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background', 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors = create_anchors(sizes=[(32,32), (16,16), (8,8)], ratios=[1], scales=[0.6, 0.7, 0.9, 1.25, 1.5])\n",
    "data.train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = RetinaNetFocalLoss(anchors)\n",
    "encoder = create_body(models.resnet50, True, -2)\n",
    "model = RetinaNet(encoder, n_classes=data.train_ds.c, n_anchors=5, sizes=[8,16,32], chs=256, final_bias=-4., n_conv=4)\n",
    "learn = Learner(data, model, loss_func=crit)#.load(\"/data/Datasets/EIPH_WSI/models/baseline-level0-rn18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_images = 0\n",
    "detect_thresh = 0.3\n",
    "nms_thresh = 0.3\n",
    "size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1055/1055 [03:41<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 9s, sys: 1min 9s, total: 4min 18s\n",
      "Wall time: 3min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_bbox_pred = []\n",
    "total_class_pred = []\n",
    "total_score_pred = []\n",
    "for xb, yb in tqdm(learn.data.train_dl):\n",
    "    file_names_batch = learn.data.train_ds.x.items[processed_images: processed_images + bs]\n",
    "    x_offset_batch, y_offset_batch = list(zip(*[fn.stem.split('_')[:2] for fn in file_names_batch]))\n",
    "\n",
    "    class_pred_batch, bbox_pred_batch = learn.model(xb)[:2] # [:, [2, 1, 0], :, :]\n",
    "\n",
    "    for clas_pred, bbox_pred, x_offset, y_offset in zip(class_pred_batch, bbox_pred_batch, x_offset_batch, y_offset_batch):\n",
    "        bbox_pred, scores, preds = process_output(clas_pred, bbox_pred, anchors, detect_thresh)\n",
    "        if bbox_pred is not None:\n",
    "            #to_keep = nms(bbox_pred, scores, nms_thresh)\n",
    "            t_sz = torch.Tensor([size, size])[None].float()\n",
    "            bbox_pred = to_np(rescale_boxes(bbox_pred.cpu(), t_sz))\n",
    "\n",
    "            bbox_pred[:, 1] = bbox_pred[:, 1] + int(x_offset)\n",
    "            bbox_pred[:, 0] = bbox_pred[:, 0] + int(y_offset)\n",
    "\n",
    "            total_bbox_pred.extend(bbox_pred)\n",
    "            total_class_pred.extend(to_np(preds))\n",
    "            total_score_pred.extend(to_np(scores))\n",
    "\n",
    "\n",
    "    processed_images += bs\n",
    "    #print(processed_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
