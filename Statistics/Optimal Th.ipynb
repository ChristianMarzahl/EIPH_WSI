{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from SlideRunner.dataAccess.database import Database\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "from Evaluator import *\n",
    "from utils import *\n",
    "from helper.nms import non_max_suppression_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('/data/Datasets/EIPH_WSI/')\n",
    "\n",
    "database = Database()\n",
    "database.open(str(path/'EIPH.sqlite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:00<00:06,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:01<00:13,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:02<00:12,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5/24 [00:02<00:08,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [00:03<00:06,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 9/24 [00:03<00:03,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [00:03<00:02,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:04<00:02,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [00:04<00:01,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:05<00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [00:05<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n",
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:06<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DB into memory ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "lbl_bbox = []\n",
    "\n",
    "getslides = \"\"\"SELECT uid, filename FROM Slides\"\"\"\n",
    "for currslide, filename in tqdm(database.execute(getslides).fetchall()):\n",
    "    database.loadIntoMemory(currslide)\n",
    "\n",
    "    check = True if 'erliner' in filename else False\n",
    "    slidetype = 'Berliner Blau/' if check else 'Turnbull Blue/'\n",
    "\n",
    "    slide_path = path / slidetype / filename\n",
    "\n",
    "    down_factor = 1\n",
    "\n",
    "    classes = {3: 0, 4: 1, 5: 2, 6: 3, 7: 4}#{3: 1, 4: 2, 5: 3, 6: 4, 7: 5} #\n",
    "    labels, bboxes = [], []\n",
    "    for id, annotation in database.annotations.items():\n",
    "        if annotation.labels[0].classId in classes:\n",
    "            d = 2 * annotation.r / down_factor\n",
    "            x_min = (annotation.x1 - annotation.r) / down_factor\n",
    "            y_min = (annotation.y1 - annotation.r) / down_factor\n",
    "            x_max = x_min + d\n",
    "            y_max = y_min + d\n",
    "            label = classes[annotation.labels[0].classId]\n",
    "\n",
    "            bboxes.append([int(x_min), int(y_min), int(x_max), int(y_max)])\n",
    "            labels.append(label)\n",
    "\n",
    "    if len(bboxes) > 0:\n",
    "        lbl_bbox.append([bboxes, labels])\n",
    "        files.append(slide_path)\n",
    "\n",
    "img2bbox = dict(zip(files, np.array(lbl_bbox)))\n",
    "get_y_func = lambda o:img2bbox[o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = pickle.load(open(\"inference_results_boxes.p\", \"rb\"))\n",
    "\n",
    "data = {'File':[],\n",
    "        'Th': [],\n",
    "        'Th IOU': [],\n",
    "        'Total GT':[],\n",
    "        'Total Pred':[],\n",
    "        'Mean GT':[],\n",
    "        'Mean Pred':[],\n",
    "        'Std GT':[],\n",
    "        'Std Pred':[],\n",
    "        'AP':[],\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c.marzahl@de.eu.local/ProgProjekte/Object-Detection-Metrics/lib/Evaluator.py:126: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rec = acc_TP / npos\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    boxes_gt, labels_gt = get_y_func(file)\n",
    "    boxes_gt, labels_gt = np.array(boxes_gt), np.array(labels_gt)\n",
    "\n",
    "    # change gt from x,y,x2,y2 -> x,y,w,h\n",
    "    boxes_gt[:, 2:] = boxes_gt[:, 2:] - boxes_gt[:, :2]\n",
    "\n",
    "    inference_data_image = np.array(inference_data[file.name])\n",
    "\n",
    "\n",
    "\n",
    "    boundingBoxes = BoundingBoxes()\n",
    "    evaluator = Evaluator()\n",
    "    for th in range(30, 70, 5):\n",
    "        for overlapThresh in range(10, 75, 5):\n",
    "\n",
    "            score_pred = inference_data_image[:, 5]\n",
    "            ids = score_pred > th / 100\n",
    "\n",
    "            nms_result = non_max_suppression_fast(inference_data_image[ids], overlapThresh / 100)\n",
    "\n",
    "            boxes_pred = nms_result[:, [0, 1, 2, 3]]\n",
    "            # change pred from x,y,x2,y2 -> x,y,w,h\n",
    "            boxes_pred[:, 2:] = boxes_pred[:, 2:] - boxes_pred[:, :2]\n",
    "            labels_pred = nms_result[:, 4]\n",
    "            score_pred = nms_result[:, 5]\n",
    "\n",
    "\n",
    "            boundingBoxes.removeAllBoundingBoxes()\n",
    "\n",
    "            ids = score_pred >= th\n",
    "\n",
    "            for box, cla in zip(boxes_gt, labels_gt):\n",
    "                temp = BoundingBox(imageName=str(file), classId=cla, x=box[0],\n",
    "                                   y=box[1],\n",
    "                                   w=box[2], h=box[3], typeCoordinates=CoordinatesType.Absolute,\n",
    "                                   bbType=BBType.GroundTruth, format=BBFormat.XYWH, imgSize=(5000, 5000))\n",
    "                boundingBoxes.addBoundingBox(temp)\n",
    "\n",
    "            for box, cla, scor in zip(boxes_pred, labels_pred, score_pred):\n",
    "                temp = BoundingBox(imageName=str(file), classId=cla, x=box[0],\n",
    "                                   y=box[1], classConfidence=scor,\n",
    "                                   w=box[2], h=box[3], typeCoordinates=CoordinatesType.Absolute,\n",
    "                                   bbType=BBType.Detected, format=BBFormat.XYWH, imgSize=(5000, 5000))\n",
    "                boundingBoxes.addBoundingBox(temp)\n",
    "\n",
    "            metricsPerClass = evaluator.GetPascalVOCMetrics(boundingBoxes, IOUThreshold=overlapThresh / 100)\n",
    "            mean_ap = np.array([mc['AP'] for mc in metricsPerClass]).mean()\n",
    "\n",
    "            data['File'].append(file.name)\n",
    "            data['Th'].append(th / 100)\n",
    "            data['Th IOU'].append(overlapThresh / 100)\n",
    "\n",
    "            data['Total GT'].append(len(labels_pred))\n",
    "            data['Total Pred'].append(len(labels_gt))\n",
    "\n",
    "            data['Std GT'].append(labels_gt.std())\n",
    "            data['Std Pred'].append(labels_pred.std())\n",
    "\n",
    "            data['Mean GT'].append(labels_gt.mean())\n",
    "            data['Mean Pred'].append(labels_pred.mean())\n",
    "\n",
    "            data['AP'].append(mean_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
